---
title: "Is Smartphone the Smarter Choice - Statistical Analysis"
author: "Hampus Lenna√°rd"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(caret)
library(knitr)
library(kableExtra)
library(rstatix)
library(stats)
library(corrplot)
library(moments)
library(ez)
library(ggpubr)
library(patchwork) # for plot wrapping 
library(car) # for aov
library(lsr) # for eta squared
library(effsize) # for effect-sizes of t.test
```

```{r function-load_csv_data, echo=FALSE, warning=FALSE, message=FALSE}
#' Loads CSV datafile 

load_xlsx <- function(file_path, sheet) {
  # Check if the file exists at the given path
  if (!file.exists(file_path)) {
    stop("The file does not exist at the specified path: ", file_path)
  }
  
  # Read the CSV data into a data frame
  data <- readxl::read_xlsx(file_path, sheet = sheet)
  
  # Return the loaded data
  return(data)
}
```
```{r call-load-data, echo=FALSE}
wcst_pc <- load_xlsx("Data_bucket/final_data.xlsx", 2)
wcst_phone <- load_xlsx("Data_bucket/final_data.xlsx", 3)

# Function to check uid consistency between two data frames
check_uid_consistency <- function(df1, df2) {
  uids_df1 <- unique(df1$uid)
  uids_df2 <- unique(df2$uid)
  all(uids_df1 %in% uids_df2) && all(uids_df2 %in% uids_df1)
}

if (check_uid_consistency(wcst_pc, wcst_phone)) {
  print("ID columns match 1-1 in both datasets")
} else {
  print("ID columns do not match 1-1 in both datasets")
}
 
full_data <- bind_rows(wcst_pc, wcst_phone) %>%
  select(-first_name)
```

```{r function-summarise_descriptives, echo=FALSE, warning=FALSE, message=FALSE}
# Calculate descriptive statistics

compute_descriptives <- function(dataframe, all_groups = FALSE) {
  # Determine the grouping variables
  groups <- if (all_groups) c("modality", "group") else "modality"
  
  # Define the columns to summarize
  columns_to_summarize <- c("total_time", "p_error", "non_p_error", 
                            "trails_first_category", "clr_percent", 
                            "correct_answers", "administrated_questions", 
                            "error_rate")
  
  # Summarize the data
  summarised_data <- dataframe %>%
    group_by(across(all_of(groups))) %>%
    summarise(across(
      all_of(columns_to_summarize),
      list(
        Mean = ~round(mean(.x, na.rm = TRUE), 3),
        Median = ~round(median(.x, na.rm = TRUE), 3),
        SD = ~round(sd(.x, na.rm = TRUE), 3)
      ),
      .names = "{.col}_{.fn}"
    ), .groups = 'drop') %>%
    pivot_longer(
      cols = ends_with("_Mean") | ends_with("_Median") | ends_with("_SD"),
      names_to = c("Variable", ".value"),
      names_pattern = "(.*)_(Mean|Median|SD)"
    )
  
  return(summarised_data)
}

# Full dataset summarization, based on modality grouping
summarised_data <- compute_descriptives(full_data)

# Dataset summarization based on modality + grouping variable 
summarised_data_groups <- compute_descriptives(full_data, all_groups = TRUE) 

```

```{r call-create-boxplot, echo=FALSE, warning=FALSE, message=FALSE}

# Function to create a combined boxplot with specified order
create_combined_boxplot <- function(full_data, y_vars) {
  
  # Ensure the variables are ordered as specified in y_vars
  y_vars_ordered <- factor(y_vars, levels = y_vars)
  
  # Create a new data frame with a 'variable' column for faceting
  plot_data <- full_data %>%
    pivot_longer(cols = all_of(y_vars), names_to = "variable", values_to = "value") %>%
    mutate(variable = factor(variable, levels = y_vars))
  
  # Create the plot with faceting
  plot <- ggplot(plot_data, aes(x = modality, y = value, fill = modality)) +
    geom_boxplot() +
    facet_wrap(~ variable, scales = "free", ncol = 2) +
    theme_minimal() +
    theme(legend.position = "none") +  # Remove legend
    labs(
      y = "Value",
      x = "Modality"
    )
  
  # Print the plot
  print(plot)
}

# List of variables to plot
y_vars <- c("clr_percent", "trails_first_category")

# Create the combined boxplot
create_combined_boxplot(full_data, y_vars)

y_vars <- c("p_error", "non_p_error")

create_combined_boxplot(full_data, y_vars)

```

```{r call-create-histograms, echo=FALSE, warning=FALSE, message=FALSE}
create_histogram <- function(full_data, var) {
    # Calculate the binwidth using the Freedman-Diaconis rule, handling NA values correctly
    data_non_na <- na.omit(full_data[[var]])  # Remove NA values from data for calculation
    bin_width <- 2 * IQR(data_non_na) / (length(data_non_na)^(1/3))
    
    # Define custom colors for modalities
    custom_colors <- c("pc" = "steelblue", "phone" = "forestgreen")

    # Create the histogram plot
    plot <- ggplot(full_data, aes(x = .data[[var]], fill = modality)) +
        geom_histogram(binwidth = bin_width, alpha = 0.7, position = "identity", color = "black") +
        scale_fill_manual(values = custom_colors) +
        theme_minimal() +
        labs(
            x = var,
            y = "Count"
        )
    return(plot)
}


# Plots for correct answer behaviour

# Variables to plot
vars_to_plot <- c("clr_percent", "trails_first_category")

# Create individual histograms
plots <- lapply(vars_to_plot, function(var) create_histogram(full_data, var))

# Combine plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 2)

# Print the combined plot
print(combined_plot)

# Plots for Error Response behaviour

# Variables to plot
vars_to_plot <- c("p_error", "non_p_error")

# Create individual histograms
plots <- lapply(vars_to_plot, function(var) create_histogram(full_data, var))

# Combine plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 2)

# Print the combined plot
print(combined_plot)

```

```{r create_group_table, echo=FALSE, warning=FALSE, message=FALSE}
group_sizes <- table(full_data$modality, full_data$group)
print(group_sizes)
```

```{r function-model_anova, echo=FALSE, warning=FALSE, message=FALSE}
model_anova <- function(dataset, response_variable) {
  set.seed(741)
  
  mod <- lm(dataset[[response_variable]] ~ modality * group, dataset)
  
  aov_res <- Anova(mod, type = 2)
  
  lev_res <- leveneTest(mod)
  
  residuals <- residuals(mod)
  
  eta_res <- etaSquared(mod, type = 2)
  
  return(list(aov_res, lev_res, residuals, eta_res))
}
```
```{r call-model_anova, echo=FALSE, warning=FALSE, message=FALSE}

aov_data <- full_data %>%
  mutate(
    modality = as.factor(modality),
    group = as.factor(group)
  )

clr_aov <- model_anova(aov_data, "clr_percent")
print(clr_aov[[1]]) # Anova res
print(clr_aov[[2]]) # Levene's test 
qqnorm(clr_aov[[3]]) # Residuals plot
print(clr_aov[[4]]) # Eta squared res 


trails_aov <- model_anova(aov_data, "trails_first_category")
print(trails_aov[[1]]) # Anova res
print(trails_aov[[2]]) # Levene's test 
qqnorm(trails_aov[[3]]) # Residuals plot
print(trails_aov[[4]]) # Eta squared res 

# Residuals does not follow a normal distribution, we will log transform and re-fit the model 
aov_data <- aov_data %>%
  mutate(
    trails_first_category_log = log(trails_first_category)
  )

trails_logged_aov <- model_anova(aov_data, "trails_first_category_log")
print(trails_logged_aov[[1]]) # Anova res
print(trails_logged_aov[[2]]) # Levene's test 
qqnorm(trails_logged_aov[[3]]) # Residuals plot
print(trails_logged_aov[[4]]) # Eta squared res 

p_error_aov <- model_anova(aov_data, "p_error")
print(p_error_aov[[1]]) # Anova res
print(p_error_aov[[2]]) # Levene's test 
qqnorm(p_error_aov[[3]]) # Residuals plot
print(p_error_aov[[4]]) # Eta squared res 


non_p_aov <- model_anova(aov_data, "non_p_error")
print(non_p_aov[[1]]) # Anova res
print(non_p_aov[[2]]) # Levene's test 
qqnorm(non_p_aov[[3]]) # Residuals plot
print(non_p_aov[[4]]) # Eta squared res 
```

**Post-Hoc Test**
Provided that there was a significant main-effect of modality on the number of PEs made between the conditions, a paired-samples t-test is used to further analyze these differences. 

```{r post-hoc analysis, echo=FALSE, message=FALSE, warning=FALSE}
t_res <- t.test(p_error ~ modality, data = aov_data, paired = TRUE)
print(t_res)

cohen_d <- cohen.d(p_error ~ modality, data = aov_data, paired = TRUE)
print(cohen_d)
```

```{r produce-bland_altman_plot, echo=FALSE, message=FALSE, warning=FALSE}
# Calculate differences
aov_data_diff <- aov_data %>%
  group_by(uid) %>%
  summarize(
    difference = p_error[modality == "phone"] - p_error[modality == "pc"]
  )


# Create a paired differences plot
ggplot(aov_data_diff, aes(x = uid, y = difference)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Paired Differences in Perseverative Errors by Participant",
       x = "Participant ID",
       y = "Difference in Perseverative Errors (Smartphone - Computer)") +
  theme_minimal()

```

```{r function-outlier_analysis, echo=FALSE, message=FALSE, warning=FALSE}
outlier_analysis <- function(long_data) {
  outlier_data <- long_data %>%
    group_by(test, modality) %>%
    identify_outliers(value)
  data.frame(outlier_data)
  
  return(outlier_data)
}
```
```{r call-outlier_analysis, echo=FALSE, message=FALSE, warning=FALSE}
outliers <- outlier_analysis(melted_data)
print(outliers)

# The data reveals some outliers / extreme cases, but then again these are Z-scores to I dont really think its valid to do an outlier analysis on them?
# Either way sample to low :()

```

```{r compute_pearson_correlations, echo=FALSE, message=FALSE, warning=FALSE}

# Reshape data for paired observations (wide format)
wide_data <- aov_data %>% 
  select(uid, modality, p_error, non_p_error, trails_first_category, clr_percent) %>%
  pivot_wider(
    names_from = modality,
    values_from = c(p_error, non_p_error, trails_first_category, clr_percent)
  )

# Calculate correlations using cor.test
pe_cor <- cor.test(wide_data$p_error_pc, wide_data$p_error_phone)
npe_cor <- cor.test(wide_data$non_p_error_pc, wide_data$non_p_error_phone)
fc_cor <- cor.test(wide_data$trails_first_category_pc, wide_data$trails_first_category_phone)
clr_cor <- cor.test(wide_data$clr_percent_pc, wide_data$clr_percent_phone)

# Create a data frame to store the results
correlations <- data.frame(
  variable = c("PE", "NPE", "FC", "%CLR"),
  correlation = c(pe_cor$estimate, npe_cor$estimate, fc_cor$estimate, clr_cor$estimate),
  p_value = c(pe_cor$p.value, npe_cor$p.value, fc_cor$p.value, clr_cor$p.value),
  conf_lower = c(pe_cor$conf.int[1], npe_cor$conf.int[1], fc_cor$conf.int[1], clr_cor$conf.int[1]),
  conf_upper = c(pe_cor$conf.int[2], npe_cor$conf.int[2], fc_cor$conf.int[2], clr_cor$conf.int[2])
)

# Print correlations
print(correlations)

# Visualize correlations
ggplot(correlations, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "darkblue", alpha = 0.7) +
  geom_text(aes(label = round(correlation, 2)), vjust = -0.5) +
  ylim(0, 1) +
  labs(title = "Correlations between Computer and Smartphone Modalities",
       x = "Variable",
       y = "Pearson Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

